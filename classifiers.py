import argparse
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

import visualizations as vis

parser = argparse.ArgumentParser("All the classifiers!")
parser.add_argument("--split_test_size", default=0.33, type=float, help="Fraction of data to be used as testing data")
parser.add_argument("--split_seed", default=42, type=int, help="Seed used to determine the train/test split of the data")
args = parser.parse_args()

csv = pd.read_csv('data/balancedData.csv')

y = csv['label']
csv = csv.drop('label', axis=1)
X = csv

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.split_test_size, random_state=args.split_seed)

def runModel(max_depth, n_estimators):
    clf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=1)
    clf.fit(X_train, y_train)
    y_predict = clf.predict(X_train)
    train_acc = accuracy_score(y_train, y_predict)
    training_cm = confusion_matrix(y_train, y_predict)

    y_predict = clf.predict(X_test)
    test_acc = accuracy_score(y_test, y_predict)

    return clf, train_acc, test_acc, training_cm


def testHyperParams(depths, estimators):
    a_training = []
    a_testing = []
    for i in depths:
        d_training = []
        d_testing = []
        for j in estimators:
            clf, train_acc, test_acc, training_cm = runModel(i, j)
            d_training.append(train_acc)
            d_testing.append(test_acc)

        a_training.append(d_training)
        a_testing.append(d_testing)

    accuracies_training = pd.DataFrame(data=a_training, columns=depths, index=estimators)
    accuracies_testing = pd.DataFrame(data=a_testing, columns=depths, index=estimators)

    print(accuracies_training)
    print(accuracies_testing)

    vis.createAccuracyHeatmap(a_training, estimators, depths, 'n_estimators', 'max_depth', 'accuracy score', 'trianing max_depth vs. n_estimators', 'training')
    vis.createAccuracyHeatmap(a_testing, estimators, depths, 'n_estimators', 'max_depth', 'accuracy score', 'testing max_depth vs. n_estimators', 'testing')


# TESTING HYPERPARAMETERS
# depths = [200, 100, 50, 10, 5]
# estimators = [5, 10, 50, 100, 200]
# testHyperParams(depths, estimators)

# RUNNING SPECIFIC HYPERPARAMETERS
clf, train_acc, test_acc, training_cm = runModel(10, 100)
print('training: ', train_acc)
print('testing: ', test_acc)

# VISUALS
vis.createDecisionTree(clf.estimators_[0], X_train.columns, 'Decision Tree', 'decision_tree')
vis.createCorrMatrix(training_cm, y.unique(), 'Random Forest Training Confusion Matrix', f'training_confusion_matrix')
vis.create3DPCAPlot(X_train, y_train, X_train.columns, 'PCA of Training Data', 'pca_training')